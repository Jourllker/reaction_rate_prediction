{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 对数据处理进行初步尝试"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from torch.utils.data import Dataset, DataLoader, Subset\n",
    "from typing import List, Tuple\n",
    "import re\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import time\n",
    "import torch.optim as optim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tokenizer，鉴于SMILES的特性，这里需要自己定义tokenizer和vocab\n",
    "# 这里直接将smiles str按字符拆分，并替换为词汇表中的序号\n",
    "class Smiles_tokenizer():\n",
    "    def __init__(self, pad_token, regex, vocab_file, max_length):\n",
    "        self.pad_token = pad_token\n",
    "        self.regex = regex\n",
    "        self.vocab_file = vocab_file\n",
    "        self.max_length = max_length\n",
    "\n",
    "        with open(self.vocab_file, \"r\") as f:\n",
    "            lines = f.readlines()\n",
    "        lines = [line.strip(\"\\n\") for line in lines]\n",
    "        vocab_dic = {}\n",
    "        for index, token in enumerate(lines):\n",
    "            vocab_dic[token] = index\n",
    "        self.vocab_dic = vocab_dic\n",
    "\n",
    "    def _regex_match(self, smiles):\n",
    "        regex_string = r\"(\" + self.regex + r\"|\"\n",
    "        regex_string += r\".)\"\n",
    "        prog = re.compile(regex_string)\n",
    "\n",
    "        tokenised = []\n",
    "        for smi in smiles:\n",
    "            tokens = prog.findall(smi)\n",
    "            if len(tokens) > self.max_length:\n",
    "                tokens = tokens[:self.max_length]\n",
    "            tokenised.append(tokens) # 返回一个所有的字符串列表\n",
    "        return tokenised\n",
    "    \n",
    "    def tokenize(self, smiles):\n",
    "        tokens = self._regex_match(smiles)\n",
    "        # 添加上表示开始和结束的token：<cls>, <end>\n",
    "        tokens = [[\"<CLS>\"] + token + [\"<SEP>\"] for token in tokens]\n",
    "        tokens = self._pad_seqs(tokens, self.pad_token)\n",
    "        token_idx = self._pad_token_to_idx(tokens)\n",
    "        return tokens, token_idx\n",
    "\n",
    "    def _pad_seqs(self, seqs, pad_token):\n",
    "        pad_length = max([len(seq) for seq in seqs])\n",
    "        padded = [seq + ([pad_token] * (pad_length - len(seq))) for seq in seqs]\n",
    "        return padded\n",
    "\n",
    "    def _pad_token_to_idx(self, tokens):\n",
    "        idx_list = []\n",
    "        for token in tokens:\n",
    "            tokens_idx = []\n",
    "            for i in token:\n",
    "                if i in self.vocab_dic.keys():\n",
    "                    tokens_idx.append(self.vocab_dic[i])\n",
    "                else:\n",
    "                    self.vocab_dic[i] = max(self.vocab_dic.values()) + 1\n",
    "                    tokens_idx.append(self.vocab_dic[i])\n",
    "            idx_list.append(tokens_idx)\n",
    "        \n",
    "        return idx_list\n",
    "\n",
    "# REGEX = r\"\\[[^\\]]+]|Br?|Cl?|N|O|S|P|F|I|b|c|n|o|s|p|\\(|\\)|\\.|=|#|-|\\+|\\\\\\\\|\\/|:|~|@|\\?|>|\\*|\\$|\\%[0-9]{2}|[0-9]\"\n",
    "# tokenizer = Smiles_tokenizer(\"<PAD>\", REGEX, \"../vocab_full.txt\", 10)\n",
    "\n",
    "# # 注意，这里一定要输入tuple（smiles1, smiles2）\n",
    "# res = tokenizer.tokenize(('[PH+][CCL2+]Clc1c(Cl)ccc(c1)[C@@H](C)[C@H](N=[N+]=[N-])C(=O)OC.C>C=O', \n",
    "#                         'Cc1cc(Br)c2c(c1)N(C(=O)O'))\n",
    "# # # res2 = tokenizer.tokenize(('[PH+][CCL2+]Clc1c(Cl)ccc(c1)[C@@H](C)[C@H](N=[N+]=[N-])C(=O)OC.C>C=O', \n",
    "# # #                           'Cc1cc(Br)c2c(c1)N(C(=O)O'))\n",
    "# print(res[0])\n",
    "# print(res[1])\n",
    "# # print(res2[0])\n",
    "# print(res2[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('c1ccc2c(c1)Nc1ccccc1O2.Brc1ccccc1I.CC(C)(C)[O-].CC(C)(C)[PH+](C(C)(C)C)C(C)(C)C.F[B-](F)(F)F.F[B-](F)(F)F.O=C(C=Cc1ccccc1)C=Cc1ccccc1.O=C(C=Cc1ccccc1)C=Cc1ccccc1.[H+].[Na+].[Pd].Cc1ccccc1>Brc1ccccc1N1c2ccccc2Oc2ccccc21',\n",
       "  0.78),\n",
       " ('c1ccc2c(c1)Nc1ccccc1O2.Brc1ccccc1I.C1COCCOCCOCCOCCOCCO1.O=C([O-])[O-].[Cu+].[I-].[K+].[K+]Clc1ccccc1Cl.Clc1ccccc1Cl>Brc1ccccc1N1c2ccccc2Oc2ccccc21',\n",
       "  0.9),\n",
       " ('c1ccc2c(c1)Nc1ccccc1O2.Brc1ccccc1I.CC(=O)[O-].CC(=O)[O-].CC(C)(C)[O-].CC(C)(C)[PH+](C(C)(C)C)C(C)(C)C.F[B-](F)(F)F.F[B-](F)(F)F.[H+].[Na+].[Pd+2].CC1(C)C=CC=CC1>Brc1ccccc1N1c2ccccc2Oc2ccccc21',\n",
       "  0.85),\n",
       " ('c1ccc2c(c1)Nc1ccccc1O2.Brc1ccccc1I.CC(C)(C)[O-].CC(C)(C)[PH+](C(C)(C)C)C(C)(C)C.F[B-](F)(F)F.F[B-](F)(F)F.O=C(C=Cc1ccccc1)C=Cc1ccccc1.O=C(C=Cc1ccccc1)C=Cc1ccccc1.[H+].[Na+].[Pd].Cc1ccccc1>Brc1ccccc1N1c2ccccc2Oc2ccccc21',\n",
       "  0.78),\n",
       " ('c1ccc2c(c1)Nc1ccccc1O2.Brc1ccccc1I.C1COCCOCCOCCOCCOCCO1.O=C([O-])[O-].[Cu+].[I-].[K+].[K+]Clc1ccccc1Cl.Clc1ccccc1Cl>Brc1ccccc1N1c2ccccc2Oc2ccccc21',\n",
       "  0.9),\n",
       " ('c1ccc2c(c1)Nc1ccccc1O2.Brc1ccccc1I.CC(=O)[O-].CC(=O)[O-].CC(C)(C)[O-].CC(C)(C)[PH+](C(C)(C)C)C(C)(C)C.F[B-](F)(F)F.F[B-](F)(F)F.[H+].[Na+].[Pd+2].CC1(C)C=CC=CC1>Brc1ccccc1N1c2ccccc2Oc2ccccc21',\n",
       "  0.85),\n",
       " ('c1ccc2c(c1)Nc1ccccc1O2.Brc1ccccc1I.CC(C)(C)[O-].CC(C)(C)[PH+](C(C)(C)C)C(C)(C)C.F[B-](F)(F)F.F[B-](F)(F)F.O=C(C=Cc1ccccc1)C=Cc1ccccc1.O=C(C=Cc1ccccc1)C=Cc1ccccc1.[H+].[Na+].[Pd].Cc1ccccc1>Brc1ccccc1N1c2ccccc2Oc2ccccc21',\n",
       "  0.78),\n",
       " ('c1ccc2c(c1)Nc1ccccc1O2.Brc1ccccc1I.C1COCCOCCOCCOCCOCCO1.O=C([O-])[O-].[Cu+].[I-].[K+].[K+]Clc1ccccc1Cl.Clc1ccccc1Cl>Brc1ccccc1N1c2ccccc2Oc2ccccc21',\n",
       "  0.9),\n",
       " ('c1ccc2c(c1)Nc1ccccc1O2.Brc1ccccc1I.CC(=O)[O-].CC(=O)[O-].CC(C)(C)[O-].CC(C)(C)[PH+](C(C)(C)C)C(C)(C)C.F[B-](F)(F)F.F[B-](F)(F)F.[H+].[Na+].[Pd+2].CC1(C)C=CC=CC1>Brc1ccccc1N1c2ccccc2Oc2ccccc21',\n",
       "  0.85)]"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 处理数据\n",
    "def read_data(file_path):\n",
    "    df = pd.read_csv(file_path)\n",
    "    reactant1 = df[\"Reactant1\"].tolist()\n",
    "    reactant2 = df[\"Reactant2\"].tolist()\n",
    "    product = df[\"Product\"].tolist()\n",
    "    additive = df[\"Additive\"].tolist()\n",
    "    solvent = df[\"Solvent\"].tolist()\n",
    "    react_yield = df[\"Yield\"].tolist()\n",
    "    \n",
    "    # 将reactant\\additive\\solvent拼到一起，之间用.分开。product也拼到一起，用>>分开\n",
    "    input_data_list = []\n",
    "    for react1, react2, prod, addi, sol in zip(reactant1, reactant2, product, additive, solvent):\n",
    "        input_info = \".\".join([react1, react2, addi, sol])\n",
    "        input_info = \">\".join([input_info, prod])\n",
    "        input_data_list.append(input_info)\n",
    "    output = [(react, y) for react, y in zip(input_data_list, react_yield)]\n",
    "    return output\n",
    "# read_data(\"../dataset/train_data_demo.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 定义数据集\n",
    "class ReactionDataset(Dataset):\n",
    "    def __init__(self, data: List[Tuple[List[str], float]]):\n",
    "        self.data = data\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        # input_info, react_yeild = self.data[idx]\n",
    "        # return input_info, react_yeild\n",
    "        return self.data[idx]\n",
    "    \n",
    "def collate_fn(batch):\n",
    "    REGEX = r\"\\[[^\\]]+]|Br?|Cl?|N|O|S|P|F|I|b|c|n|o|s|p|\\(|\\)|\\.|=|#|-|\\+|\\\\\\\\|\\/|:|~|@|\\?|>|\\*|\\$|\\%[0-9]{2}|[0-9]\"\n",
    "    tokenizer = Smiles_tokenizer(\"<PAD>\", REGEX, \"../vocab_full.txt\", 10)\n",
    "    smi_list = []\n",
    "    yield_list = []\n",
    "    for i in batch:\n",
    "        smi_list.append(i[0])\n",
    "        yield_list.append(i[1])\n",
    "    tokenizer_batch = torch.tensor(tokenizer.tokenize(smi_list)[1])\n",
    "    yield_list = torch.tensor(yield_list)\n",
    "    return tokenizer_batch, yield_list\n",
    "\n",
    "# res1, res2 = collate_fn([('Clc1c(Cl)ccc(c1)[C@@H](C)[C@H](N=[N+]=[N-])C(=O)OC.C>C=O', 0.1), ('Cc1cc(Br)c2c(c1)N(C(=O)O', 0.2)])\n",
    "# print(res1)\n",
    "# print(res2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = read_data(\"../dataset/train_data_demo.csv\")\n",
    "# REGEX = r\"\\[[^\\]]+]|Br?|Cl?|N|O|S|P|F|I|b|c|n|o|s|p|\\(|\\)|\\.|=|#|-|\\+|\\\\\\\\|\\/|:|~|@|\\?|>|\\*|\\$|\\%[0-9]{2}|[0-9]\"\n",
    "# tokenizer = Smiles_tokenizer(\"<PAD>\", REGEX, \"../vocab_full.txt\") \n",
    "dataset = ReactionDataset(data, None)\n",
    "# 选择数据集的前N个样本进行训练\n",
    "N = 1  #int(len(dataset) * 1)  # 或者你可以设置为数据集大小的一定比例，如 int(len(dataset) * 0.1)\n",
    "subset_indices = list(range(3))\n",
    "subset_dataset = Subset(dataset, subset_indices)\n",
    "train_loader = DataLoader(subset_dataset, batch_size=2, shuffle=True, collate_fn=collate_fn)\n",
    "# for i, (src, trg) in enumerate(train_loader):\n",
    "#     print(src)\n",
    "#     print(trg)\n",
    "#     raise KeyError"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 模型\n",
    "'''\n",
    "直接采用一个transformer encoder model就好了\n",
    "'''\n",
    "class TransformerEncoderModel(nn.Module):\n",
    "    def __init__(self, input_dim, d_model, num_heads, fnn_dim, num_layers, dropout):\n",
    "        super().__init__()\n",
    "        self.embedding = nn.Embedding(input_dim, d_model)\n",
    "        self.encoder_layer = nn.TransformerEncoderLayer(d_model=d_model, \n",
    "                                                        nhead=num_heads, \n",
    "                                                        dim_feedforward=fnn_dim,\n",
    "                                                        dropout=dropout\n",
    "                                                        )\n",
    "        self.transformer_encoder = nn.TransformerEncoder(self.encoder_layer, num_layers=num_layers)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        self.l1 = nn.Linear(d_model, 96)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.out = nn.Linear(96, 1)\n",
    "\n",
    "    def forward(self, src):\n",
    "        # src shape: [batch_size, src_len]\n",
    "        embedded = self.dropout(self.embedding(src))\n",
    "        # embedded shape: [batch_size, src_len, d_model]\n",
    "        outputs = self.transformer_encoder(embedded)\n",
    "        # outputs shape: [batch_size, src_len, d_model]\n",
    "\n",
    "        # fisrt\n",
    "        z = outputs[:,0,:].squeeze(1)\n",
    "        # z shape: [bs, d_model]\n",
    "        outputs = self.out(self.relu(self.l1(z)))\n",
    "        # outputs shape: [bs, 1]\n",
    "        return outputs.squeeze(-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/xc/miniconda3/envs/usual_torch/lib/python3.10/site-packages/torch/nn/modules/transformer.py:282: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.batch_first was not True(use batch_first for better inference performance)\n",
      "  warnings.warn(f\"enable_nested_tensor is True, but self.use_nested_tensor is False because {why_not_sparsity_fast_path}\")\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "CUDA error: device-side assert triggered\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[109], line 56\u001b[0m\n\u001b[1;32m     53\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTotal running time: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00melapsed_time_minute\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.2f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m minutes\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     55\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;18m__name__\u001b[39m \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m__main__\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[0;32m---> 56\u001b[0m     \u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[109], line 25\u001b[0m, in \u001b[0;36mtrain\u001b[0;34m()\u001b[0m\n\u001b[1;32m     22\u001b[0m train_loader \u001b[38;5;241m=\u001b[39m DataLoader(dataset, batch_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m3\u001b[39m, shuffle\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, collate_fn\u001b[38;5;241m=\u001b[39mcollate_fn)\n\u001b[1;32m     24\u001b[0m model \u001b[38;5;241m=\u001b[39m TransformerEncoderModel(INPUT_DIM, D_MODEL, NUM_HEADS, FNN_DIM, NUM_LAYERS, DROPOUT)\n\u001b[0;32m---> 25\u001b[0m model \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     26\u001b[0m \u001b[38;5;66;03m# model.to(device)\u001b[39;00m\n\u001b[1;32m     27\u001b[0m \u001b[38;5;66;03m# raise KeyError\u001b[39;00m\n\u001b[1;32m     28\u001b[0m model\u001b[38;5;241m.\u001b[39mtrain()\n",
      "File \u001b[0;32m~/miniconda3/envs/usual_torch/lib/python3.10/site-packages/torch/nn/modules/module.py:1160\u001b[0m, in \u001b[0;36mModule.to\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1156\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m t\u001b[38;5;241m.\u001b[39mto(device, dtype \u001b[38;5;28;01mif\u001b[39;00m t\u001b[38;5;241m.\u001b[39mis_floating_point() \u001b[38;5;129;01mor\u001b[39;00m t\u001b[38;5;241m.\u001b[39mis_complex() \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m   1157\u001b[0m                     non_blocking, memory_format\u001b[38;5;241m=\u001b[39mconvert_to_format)\n\u001b[1;32m   1158\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m t\u001b[38;5;241m.\u001b[39mto(device, dtype \u001b[38;5;28;01mif\u001b[39;00m t\u001b[38;5;241m.\u001b[39mis_floating_point() \u001b[38;5;129;01mor\u001b[39;00m t\u001b[38;5;241m.\u001b[39mis_complex() \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m, non_blocking)\n\u001b[0;32m-> 1160\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_apply\u001b[49m\u001b[43m(\u001b[49m\u001b[43mconvert\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/usual_torch/lib/python3.10/site-packages/torch/nn/modules/module.py:810\u001b[0m, in \u001b[0;36mModule._apply\u001b[0;34m(self, fn, recurse)\u001b[0m\n\u001b[1;32m    808\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m recurse:\n\u001b[1;32m    809\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mchildren():\n\u001b[0;32m--> 810\u001b[0m         \u001b[43mmodule\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_apply\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfn\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    812\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcompute_should_use_set_data\u001b[39m(tensor, tensor_applied):\n\u001b[1;32m    813\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m torch\u001b[38;5;241m.\u001b[39m_has_compatible_shallow_copy_type(tensor, tensor_applied):\n\u001b[1;32m    814\u001b[0m         \u001b[38;5;66;03m# If the new tensor has compatible tensor type as the existing tensor,\u001b[39;00m\n\u001b[1;32m    815\u001b[0m         \u001b[38;5;66;03m# the current behavior is to change the tensor in-place using `.data =`,\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    820\u001b[0m         \u001b[38;5;66;03m# global flag to let the user control whether they want the future\u001b[39;00m\n\u001b[1;32m    821\u001b[0m         \u001b[38;5;66;03m# behavior of overwriting the existing tensor or not.\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/usual_torch/lib/python3.10/site-packages/torch/nn/modules/module.py:833\u001b[0m, in \u001b[0;36mModule._apply\u001b[0;34m(self, fn, recurse)\u001b[0m\n\u001b[1;32m    829\u001b[0m \u001b[38;5;66;03m# Tensors stored in modules are graph leaves, and we don't want to\u001b[39;00m\n\u001b[1;32m    830\u001b[0m \u001b[38;5;66;03m# track autograd history of `param_applied`, so we have to use\u001b[39;00m\n\u001b[1;32m    831\u001b[0m \u001b[38;5;66;03m# `with torch.no_grad():`\u001b[39;00m\n\u001b[1;32m    832\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mno_grad():\n\u001b[0;32m--> 833\u001b[0m     param_applied \u001b[38;5;241m=\u001b[39m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mparam\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    834\u001b[0m should_use_set_data \u001b[38;5;241m=\u001b[39m compute_should_use_set_data(param, param_applied)\n\u001b[1;32m    835\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m should_use_set_data:\n",
      "File \u001b[0;32m~/miniconda3/envs/usual_torch/lib/python3.10/site-packages/torch/nn/modules/module.py:1158\u001b[0m, in \u001b[0;36mModule.to.<locals>.convert\u001b[0;34m(t)\u001b[0m\n\u001b[1;32m   1155\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m convert_to_format \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m t\u001b[38;5;241m.\u001b[39mdim() \u001b[38;5;129;01min\u001b[39;00m (\u001b[38;5;241m4\u001b[39m, \u001b[38;5;241m5\u001b[39m):\n\u001b[1;32m   1156\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m t\u001b[38;5;241m.\u001b[39mto(device, dtype \u001b[38;5;28;01mif\u001b[39;00m t\u001b[38;5;241m.\u001b[39mis_floating_point() \u001b[38;5;129;01mor\u001b[39;00m t\u001b[38;5;241m.\u001b[39mis_complex() \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m   1157\u001b[0m                 non_blocking, memory_format\u001b[38;5;241m=\u001b[39mconvert_to_format)\n\u001b[0;32m-> 1158\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mt\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mt\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mis_floating_point\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mt\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mis_complex\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnon_blocking\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: CUDA error: device-side assert triggered\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n"
     ]
    }
   ],
   "source": [
    "# 训练\n",
    "def train():\n",
    "    ## super param\n",
    "    N = 6  #int(len(dataset) * 1)  # 或者你可以设置为数据集大小的一定比例，如 int(len(dataset) * 0.1)\n",
    "    INPUT_DIM = 300 # src length\n",
    "    D_MODEL = 512\n",
    "    NUM_HEADS = 4\n",
    "    FNN_DIM = 1024\n",
    "    NUM_LAYERS = 6\n",
    "    DROPOUT = 0.5\n",
    "    CLIP = 1 # CLIP value\n",
    "    N_EPOCHS = 2\n",
    "    LR = 0.001\n",
    "    \n",
    "    start_time = time.time()  # 开始计时\n",
    "    # device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "    device = 'cpu'\n",
    "    data = read_data(\"../dataset/train_data_demo.csv\")\n",
    "    dataset = ReactionDataset(data)\n",
    "    subset_indices = list(range(N))\n",
    "    subset_dataset = Subset(dataset, subset_indices)\n",
    "    train_loader = DataLoader(dataset, batch_size=3, shuffle=True, collate_fn=collate_fn)\n",
    "\n",
    "    model = TransformerEncoderModel(INPUT_DIM, D_MODEL, NUM_HEADS, FNN_DIM, NUM_LAYERS, DROPOUT)\n",
    "    model = model.to(device)\n",
    "    # model.to(device)\n",
    "    # raise KeyError\n",
    "    model.train()\n",
    "    \n",
    "    optimizer = optim.SGD(model.parameters(), lr=LR)\n",
    "    criterion = nn.MSELoss()\n",
    "\n",
    "    for epoch in range(N_EPOCHS):\n",
    "        epoch_loss = 0\n",
    "        for i, (src, y) in enumerate(train_loader):\n",
    "            src, y = src.to(device), y.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            output = model(src)\n",
    "            loss = criterion(output, y)\n",
    "            loss.backward()\n",
    "            torch.nn.utils.clip_grad_norm_(model.parameters(), CLIP)\n",
    "            optimizer.step()\n",
    "            # raise KeyError\n",
    "            epoch_loss += loss.item()\n",
    "            loss_in_a_epoch = epoch_loss / len(train_loader)\n",
    "        print(f'Epoch: {epoch+1:02} | Train Loss: {loss_in_a_epoch:.3f}')\n",
    "\n",
    "    # 在训练循环结束后保存模型\n",
    "    torch.save(model.state_dict(), './translation_model_GRU.pth')\n",
    "    end_time = time.time()  # 结束计时\n",
    "    # 计算并打印运行时间\n",
    "    elapsed_time_minute = (end_time - start_time)/60\n",
    "    print(f\"Total running time: {elapsed_time_minute:.2f} minutes\")\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "usual",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
